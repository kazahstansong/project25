# ==============================================
# âš™ï¸ AI ê¸°ë°˜ ì¥ì•  ëŒ€ì‘ ìƒí™©ì°½ ì–´ì‹œìŠ¤í„´íŠ¸ (RAG + Azure Search)
# ==============================================
import os
import streamlit as st
from dotenv import load_dotenv
from pathlib import Path
from langchain_openai import AzureChatOpenAI, AzureOpenAIEmbeddings
from langchain_community.vectorstores.azuresearch import AzureSearch
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnableParallel, RunnablePassthrough
import json
import warnings
import re
warnings.filterwarnings("ignore", category=RuntimeWarning)

# ---------------------------------------------------------------------
# í™˜ê²½ ì„¤ì •
# ---------------------------------------------------------------------
load_dotenv()

# ë¡œê·¸ ë””ë ‰í† ë¦¬ ìë™ ìƒì„±
os.makedirs("logs", exist_ok=True)
from datetime import datetime
log_path = Path("logs") / "incident_history.json"

# ğŸ”¹ OpenAI ì„¤ì •
AZURE_OPENAI_ENDPOINT = os.getenv("AZURE_OPENAI_ENDPOINT")
AZURE_OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
AZURE_OPENAI_API_VERSION = os.getenv("AZURE_OPENAI_API_VERSION")
AZURE_OPENAI_DEPLOYMENT = os.getenv("AZURE_OPENAI_DEPLOYMENT")

# ğŸ”¹ Azure Search ì„¤ì •
AZURE_SEARCH_ENDPOINT = os.getenv("AZURE_SEARCH_ENDPOINT")
AZURE_SEARCH_KEY = os.getenv("AZURE_SEARCH_API_KEY")
AZURE_SEARCH_INDEX = os.getenv("AZURE_SEARCH_INDEX")

# ğŸ”¹ Embedding ì„¤ì •
AZURE_EMBEDDING_MODEL = os.getenv("AZURE_EMBEDDING_MODEL")
AZURE_EMBEDDING_DEPLOYMENT = os.getenv("AZURE_EMBEDDING_DEPLOYMENT")
AZURE_EMBEDDING_ENDPOINT = os.getenv("AZURE_EMBEDDING_ENDPOINT")

# í…œí”Œë¦¿ íŒŒì¼ ë¡œë“œ
BASE_DIR = Path(__file__).resolve().parent
data_dir = BASE_DIR / "data"
template_path = data_dir / "incident_template.txt"

if not template_path.exists():
    st.error(f"í…œí”Œë¦¿ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {template_path}")
    st.stop()

with template_path.open("r", encoding="utf-8") as f:
    incident_template = f.read()

# ğŸ”§ ë””ë²„ê¹…ìš© í—¬í¼ í•¨ìˆ˜
def debug_log(title, value):
    print(f"\n===== ğŸ” {title} =====")
    try:
        if isinstance(value, dict):
            print(json.dumps(value, indent=2, ensure_ascii=False))
        else:
            print(str(value)[:1000])  # ë„ˆë¬´ ê¸¸ë©´ 1000ìê¹Œì§€ë§Œ í‘œì‹œ
    except Exception as e:
        print(f"(âš ï¸ ë””ë²„ê¹… ì¶œë ¥ ì¤‘ ì˜¤ë¥˜: {e})")
    print("========================\n")

st.set_page_config(page_title="AI ê¸°ë°˜ ì¥ì•  ëŒ€ì‘ ìƒí™©ì°½ ì–´ì‹œìŠ¤í„´íŠ¸", layout="wide")
st.title("âš™ï¸ AI ê¸°ë°˜ ì¥ì•  ëŒ€ì‘ ìƒí™©ì°½ ì–´ì‹œìŠ¤í„´íŠ¸")


# ==============================================
# ğŸ§­ íƒ­ ìƒíƒœ ê´€ë¦¬
# ==============================================
if "active_tab" not in st.session_state:
    st.session_state.active_tab = "tab1"  # ì´ˆê¸°: tab1 í™œì„±í™”
if "messages" not in st.session_state:
    st.session_state.messages = []

# ==============================================
# ğŸ¨ íƒ­ ë²„íŠ¼
# ==============================================
col1, col2 = st.columns(2)
with col1:
    if st.button("ğŸ’¬ ìƒí™©ì°½", use_container_width=True):
        st.session_state.active_tab = "tab1"
with col2:
    if st.button("ğŸ“ ë³´ê³ ì„œ", use_container_width=True):
        st.session_state.active_tab = "tab2"

# ==============================================
# ğŸ¨ CSS ìŠ¤íƒ€ì¼
# ==============================================
st.markdown("""
<style>
.tab-div {
    padding: 30px;
    border-radius: 12px;
    height: 75vh;
    overflow-y: auto;
}
.tab1-div {
    /* background-color: #f5f0e1;   ë² ì´ì§€ */
    height: 10px;
}
.tab2-div {
    /*  background-color: #d9d9d9;  ê·¸ë ˆì´ */
    height: 10px;
}
.chat-bubble {
    max-width: 75%;
    padding: 0.8rem 1rem;
    border-radius: 1rem;
    margin: 0.4rem 0;
    word-wrap: break-word;
}
.user-msg {
    background-color: #E1E9F6;
    margin-left: auto;
    text-align: left;
}
.assistant-msg {
    background-color: #F1F0F0;
    margin-right: auto;
    text-align: left;
}
</style>
""", unsafe_allow_html=True)

# LangChain êµ¬ì„± (RAG)
try:
    # 1ï¸âƒ£ Embedding ìƒì„±
    embeddings = AzureOpenAIEmbeddings(
        azure_endpoint=AZURE_EMBEDDING_ENDPOINT,
        azure_deployment=AZURE_EMBEDDING_DEPLOYMENT,
        api_key=AZURE_OPENAI_API_KEY,
        model=AZURE_EMBEDDING_MODEL
    )
    print("ğŸ”§ AZURE_EMBEDDING_MODEL:", os.getenv("AZURE_EMBEDDING_MODEL"))
    print("ğŸ”§ AZURE_EMBEDDING_DEPLOYMENT:", os.getenv("AZURE_EMBEDDING_DEPLOYMENT"))

    # 2ï¸âƒ£ Azure AI Search ì—°ê²°
    vector_store = AzureSearch(
        azure_search_endpoint=AZURE_SEARCH_ENDPOINT,
        azure_search_key=AZURE_SEARCH_KEY,
        index_name=AZURE_SEARCH_INDEX,
        embedding_function=embeddings,
        vector_field="content_vector",
        text_field="content"
    )

    print("ğŸ”— í˜„ì¬ ì—°ê²°ëœ Azure ì¸ë±ìŠ¤:", AZURE_SEARCH_INDEX)
    print("ğŸ”— í˜„ì¬ ì—°ê²°ëœ Azure ì—”ë“œí¬ì¸íŠ¸:", AZURE_SEARCH_ENDPOINT)

    print("ğŸ” AzureSearch í…ŒìŠ¤íŠ¸ ì¤‘...")
    

    # ğŸ“„ Retriever ìƒì„±
    retriever = vector_store.as_retriever(
        search_type="hybrid",
        k=5
    )

    # 3ï¸âƒ£ LLM ì´ˆê¸°í™”
    llm = AzureChatOpenAI(
        azure_endpoint=AZURE_OPENAI_ENDPOINT,
        api_key=AZURE_OPENAI_API_KEY,
        api_version=AZURE_OPENAI_API_VERSION,
        deployment_name=AZURE_OPENAI_DEPLOYMENT,
        temperature=0.2
    )




    # 4ï¸âƒ£ í”„ë¡¬í”„íŠ¸ ì •ì˜ (í…œí”Œë¦¿ + ë¬¸ì„œ ê¸°ë°˜)
    prompt = ChatPromptTemplate.from_template("""
    ë„ˆëŠ” ì‹œìŠ¤í…œ ì¥ì•  ëŒ€ì‘ì„ ì§€ì›í•˜ëŠ” ì–´ì‹œìŠ¤í„´íŠ¸ì•¼.
    ì•„ë˜ ë§¤ë‰´ì–¼ê³¼ í…œí”Œë¦¿ì„ ì°¸ê³ í•´ ìƒí™©ì°½ ëŒ€í™”ë¥¼ ì¤‘ê°„ë³´ê³  í˜•ì‹ìœ¼ë¡œ ì •ë¦¬í•´ì¤˜.

    [í˜„ì¬ ë³´ê³ ìœ í˜•]
    {report_type}
                                              
    [ì¥ì•  ëŒ€ì‘ í…œí”Œë¦¿]
    {template}

    [ê´€ë ¨ ë¬¸ì„œ ë‚´ìš©]
    {context}

    [ìƒí™©ì°½ ë©”ì‹œì§€]
    {question}
    """)

    # 5ï¸âƒ£ ì²´ì¸ ìƒì„±
    rag_chain = (
        {"context": retriever, "question": RunnablePassthrough(), "report_type": RunnablePassthrough()}
        | prompt
        | llm
    )
except Exception as e:
    st.error(f"LangChain ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    st.stop()


# ==============================================
# ğŸ’¬ TAB 1 - ìƒí™©ì°½ (Chat ê¸°ëŠ¥)
# ==============================================
if st.session_state.active_tab == "tab1":
    st.markdown("<div class='tab-div tab1-div'>", unsafe_allow_html=True)
    st.markdown("### ğŸŸ¤ ìƒí™©ì°½ (í™œì„±í™”ë¨)")

    chat_container = st.container()



    user_input = st.chat_input("ğŸ—¨ ìƒí™©ì°½ ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: ERP ë¡œê·¸ì¸ ì˜¤ë¥˜, DB ì ‘ì† ë¶ˆê°€, ë³µêµ¬ ì§„í–‰ ì¤‘...)")

    # âœ… ëŒ€í™” ì¶œë ¥
    with chat_container:
        for msg in st.session_state.messages:
            #st.chat_message(msg["role"]).markdown(msg["content"], unsafe_allow_html=True)
            role_class = "user-msg" if msg["role"] == "user" else "assistant-msg"
            st.markdown(f"<div class='chat-bubble {role_class}'>{msg['content']}</div>", unsafe_allow_html=True)

    if user_input:
        # ì‚¬ìš©ì ë©”ì‹œì§€
        st.markdown(
            f"<div class='chat-bubble user-msg'>{user_input.replace(chr(10), '<br>')}</div>",
            unsafe_allow_html=True
        )
        #st.chat_message("user").markdown(user_input.replace("\n", "<br>"), unsafe_allow_html=True)
        st.session_state["messages"].append({"role": "user", "content": user_input})

        if "ë³µêµ¬ ì™„ë£Œ" in user_input or "ì •ìƒí™”" in user_input:
            report_type = "ìµœì¢…ë³´ê³ "
        else:
            report_type = "ì¤‘ê°„ë³´ê³ "


        # âœ… ì´ì „ ëŒ€í™” í¬í•¨
        chat_history = "\n".join([f"{m['role']}: {m['content']}" for m in st.session_state["messages"]])
        query_with_context = f"{chat_history}\nuser: {user_input}"

        with st.spinner("AIê°€ "+report_type+"ë¥¼ ì‘ì„±ì¤‘ì…ë‹ˆë‹¤..."):
            try:
                rag_input = {"question": query_with_context, "template": incident_template, "report_type": report_type}

                retriever_output = retriever.invoke(query_with_context)
                context_texts = "\n".join([d.page_content for d in retriever_output]) if retriever_output else ""

                prompt_input = {
                    "context": context_texts,
                    "question": query_with_context,
                    "template": incident_template,
                    "report_type": report_type
                }

                # ğŸ”¹ LLM í˜¸ì¶œ
                raw_llm_response = llm.invoke(prompt.format(**prompt_input))
                ai_output = str(raw_llm_response)

                print("\nğŸ” input: "+ prompt.format(**prompt_input))
                print("\nğŸ” output: "+ ai_output)
        

                # ğŸ”¹ content ë¶€ë¶„ë§Œ ì¶”ì¶œ
                match = re.search(r"content='(.*?)' additional_kwargs=", ai_output, re.DOTALL)
                if match:
                    content_text = match.group(1).strip()
                else:
                    content_text = ai_output.strip()

                # ğŸ”¹ \n â†’ ì¤„ë°”ê¿ˆ ë³µì›
                content_text = content_text.replace("\\n", "\n")

            
                st.session_state.messages.append({"role": "assistant", "content": content_text})
                st.chat_message("assistant").markdown(content_text)

            

                # ğŸ”¹ ë¡œê·¸ ì €ì¥
                log_data = {
                    "timestamp": datetime.now().isoformat(),
                    "input": user_input,
                    "output": content_text
                }

                with open(log_path, "a", encoding="utf-8") as f:
                    json.dump(log_data, f, ensure_ascii=False)
                    f.write("\n")

            except Exception as e:
                st.error(f"RAG ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

        st.markdown("</div>", unsafe_allow_html=True)

# ==============================================
# ğŸ“ TAB 2 - ë³´ê³ ì„œ (ë‹¨ìˆœ í‘œì‹œìš©)
# ==============================================
elif st.session_state.active_tab == "tab2":
    st.markdown("<div class='tab-div tab2-div'>", unsafe_allow_html=True)
    st.markdown("### âšª ë³´ê³ ì„œ (í™œì„±í™”ë¨)")
    st.write("ì´ ì˜ì—­ì€ ë³´ê³ ì„œ í‘œì‹œìš© ê³µê°„ì…ë‹ˆë‹¤.")
    st.markdown("</div>", unsafe_allow_html=True)

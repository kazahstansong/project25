# ==============================================
# âš™ï¸ AI ê¸°ë°˜ ì¥ì•  ëŒ€ì‘ ìƒí™©ì°½ ì–´ì‹œìŠ¤í„´íŠ¸ (RAG + Azure Search)
# ==============================================
import os
import streamlit as st
from dotenv import load_dotenv
from pathlib import Path
from langchain_openai import AzureChatOpenAI, AzureOpenAIEmbeddings
from langchain_community.vectorstores.azuresearch import AzureSearch
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnableParallel, RunnablePassthrough
import json
import warnings
import re
import random

warnings.filterwarnings("ignore", category=RuntimeWarning)

# ---------------------------------------------------------------------
# í™˜ê²½ ì„¤ì •
# ---------------------------------------------------------------------
load_dotenv()

# ë¡œê·¸ ë””ë ‰í† ë¦¬ ìë™ ìƒì„±
os.makedirs("logs", exist_ok=True)
from datetime import datetime
log_path = Path("logs") / "incident_history.json"

# ğŸ”¹ OpenAI ì„¤ì •
AZURE_OPENAI_ENDPOINT = os.getenv("AZURE_OPENAI_ENDPOINT")
AZURE_OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
AZURE_OPENAI_API_VERSION = os.getenv("AZURE_OPENAI_API_VERSION")
AZURE_OPENAI_DEPLOYMENT = os.getenv("AZURE_OPENAI_DEPLOYMENT")

# ğŸ”¹ Azure Search ì„¤ì •
AZURE_SEARCH_ENDPOINT = os.getenv("AZURE_SEARCH_ENDPOINT")
AZURE_SEARCH_KEY = os.getenv("AZURE_SEARCH_API_KEY")
AZURE_SEARCH_INDEX = os.getenv("AZURE_SEARCH_INDEX")

# ğŸ”¹ Embedding ì„¤ì •
AZURE_EMBEDDING_MODEL = os.getenv("AZURE_EMBEDDING_MODEL")
AZURE_EMBEDDING_DEPLOYMENT = os.getenv("AZURE_EMBEDDING_DEPLOYMENT")
AZURE_EMBEDDING_ENDPOINT = os.getenv("AZURE_EMBEDDING_ENDPOINT")

# í…œí”Œë¦¿ íŒŒì¼ ë¡œë“œ
BASE_DIR = Path(__file__).resolve().parent
data_dir = BASE_DIR / "data"
template_path = data_dir / "incident_template.txt"

if not template_path.exists():
    st.error(f"í…œí”Œë¦¿ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {template_path}")
    st.stop()

with template_path.open("r", encoding="utf-8") as f:
    incident_template = f.read()


# ğŸ”¹ ì¢Œ / ë©”ì¸ / ìš° êµ¬ì¡° ì •ì˜
left_col, main_col, right_col = st.columns([0.05, 0.7, 0.25], gap="large")




st.set_page_config(page_title="AI ê¸°ë°˜ ì¥ì•  ëŒ€ì‘ ìƒí™©ì°½ ì–´ì‹œìŠ¤í„´íŠ¸", layout="wide")
 
# ==============================================
# ğŸ§­ íƒ­ ìƒíƒœ ê´€ë¦¬
# ==============================================
if "active_tab" not in st.session_state:
    st.session_state.active_tab = "tab1"
if "messages" not in st.session_state:
    st.session_state.messages = []
if "reports" not in st.session_state:
    st.session_state.reports = []

# ğŸ”¹ ì¢Œì¸¡ íŒ¨ë„ êµ¬ì„±
with st.sidebar:
    st.header("ğŸ§­ ë©”ë‰´")
    st.write("ì•„ë˜ íƒ­ì„ ì„ íƒí•˜ì„¸ìš”.")
    if st.button("ğŸ’¬ ìƒí™©ì°½ ë¶„ì„", use_container_width=True):
        st.session_state.active_tab = "tab1"
    if st.button("ğŸ“ ë³´ê³ ì„œ", use_container_width=True):
        st.session_state.active_tab = "tab2"

    st.markdown("---")
    st.markdown("### âš™ï¸ ë¹ ë¥¸ ì œì–´")

    if st.button("ğŸ§¹ ëŒ€í™” ì´ˆê¸°í™”", use_container_width=True):
        st.session_state["messages"] = []
        st.rerun()

    if st.button("ğŸ“ ë³´ê³ ì„œ ì´ˆê¸°í™”", use_container_width=True):
        st.session_state["reports"] = []
        st.rerun()

    if st.button("ğŸ”„ ì „ì²´ ìƒˆë¡œê³ ì¹¨", use_container_width=True):
        for key in list(st.session_state.keys()):
            del st.session_state[key]
        st.rerun()

    st.markdown("---")
    st.subheader("âš™ï¸ ì„¤ì •")
    st.text_input("Azure Search ì¸ë±ìŠ¤", AZURE_SEARCH_INDEX, disabled=True)
    st.text_input("ëª¨ë¸ ë°°í¬ ì´ë¦„", AZURE_OPENAI_DEPLOYMENT, disabled=True)
    st.markdown("---")



    st.caption("Â© 2025 AI ê¸°ë°˜ ì¥ì•  ëŒ€ì‘ ì–´ì‹œìŠ¤í„´íŠ¸")

# ==============================================
# ğŸ¨ CSS ìŠ¤íƒ€ì¼
# ==============================================
st.markdown("""
<style>
.tab-div {
    padding: 30px;
    border-radius: 12px;
    height: 75vh;
    overflow-y: auto;
}
.tab1-div {
    /* background-color: #f5f0e1;   ë² ì´ì§€ */
    height: 10px;
}
.tab2-div {
    /*  background-color: #d9d9d9;  ê·¸ë ˆì´ */
    height: 10px;
}
.chat-bubble {
    max-width: 75%;
    padding: 0.8rem 1rem;
    border-radius: 1rem;
    margin: 0.4rem 0;
    word-wrap: break-word;
}
.user-msg {
    background-color: #E1E9F6;
    margin-left: auto;
    text-align: left;
}
.assistant-msg {
    background-color: #F1F0F0;
    margin-right: auto;
    text-align: left;
}
[data-testid="stSpinnerOverlay"] {
    background-color: rgba(255, 255, 255, 1) !important;
    opacity: 1 !important;
}
html, body, [class*="css"]  {
    font-size: 11px;   /* ê¸°ë³¸ê°’ ì•½ 16px â†’ 14pxë¡œ ì¶•ì†Œ */
}
.right-panel {
    position: fixed;
    top: 80px;
    right: 0;
    width: 22%;
    height: 90%;
    padding: 20px;
    background-color: #f8f9fa;
    border-left: 2px solid #ddd;
    overflow-y: auto;
    box-shadow: -2px 0 8px rgba(0,0,0,0.1);
}
.main-content {
    margin-right: 25%;
}
</style>
""", unsafe_allow_html=True)

# LangChain êµ¬ì„± (RAG)
try:
    # 1ï¸âƒ£ Embedding ìƒì„±
    embeddings = AzureOpenAIEmbeddings(
        azure_endpoint=AZURE_EMBEDDING_ENDPOINT,
        azure_deployment=AZURE_EMBEDDING_DEPLOYMENT,
        api_key=AZURE_OPENAI_API_KEY,
        model=AZURE_EMBEDDING_MODEL
    )
    print("ğŸ”§ AZURE_EMBEDDING_MODEL:", os.getenv("AZURE_EMBEDDING_MODEL"))
    print("ğŸ”§ AZURE_EMBEDDING_DEPLOYMENT:", os.getenv("AZURE_EMBEDDING_DEPLOYMENT"))

    # 2ï¸âƒ£ Azure AI Search ì—°ê²°
    vector_store = AzureSearch(
        azure_search_endpoint=AZURE_SEARCH_ENDPOINT,
        azure_search_key=AZURE_SEARCH_KEY,
        index_name=AZURE_SEARCH_INDEX,
        embedding_function=embeddings,
        vector_field="content_vector",
        text_field="content"
    )

    print("ğŸ”— í˜„ì¬ ì—°ê²°ëœ Azure ì¸ë±ìŠ¤:", AZURE_SEARCH_INDEX)
    print("ğŸ”— í˜„ì¬ ì—°ê²°ëœ Azure ì—”ë“œí¬ì¸íŠ¸:", AZURE_SEARCH_ENDPOINT)

    print("ğŸ” AzureSearch í…ŒìŠ¤íŠ¸ ì¤‘...")
    

    # ğŸ“„ Retriever ìƒì„±
    retriever = vector_store.as_retriever(
        search_type="hybrid",
        k=5
    )

    # 3ï¸âƒ£ LLM ì´ˆê¸°í™”
    llm = AzureChatOpenAI(
        azure_endpoint=AZURE_OPENAI_ENDPOINT,
        api_key=AZURE_OPENAI_API_KEY,
        api_version=AZURE_OPENAI_API_VERSION,
        deployment_name=AZURE_OPENAI_DEPLOYMENT,
        temperature=0.2
    )




    # 4ï¸âƒ£ í”„ë¡¬í”„íŠ¸ ì •ì˜ (í…œí”Œë¦¿ + ë¬¸ì„œ ê¸°ë°˜)
    prompt = ChatPromptTemplate.from_template("""
    ë„ˆëŠ” ì‹œìŠ¤í…œ ì¥ì•  ëŒ€ì‘ì„ ì§€ì›í•˜ëŠ” ì–´ì‹œìŠ¤í„´íŠ¸ì•¼.
    ì•„ë˜ ë§¤ë‰´ì–¼ê³¼ í…œí”Œë¦¿ì„ ì°¸ê³ í•´ ìƒí™©ì°½ ëŒ€í™”ë¥¼ ì¤‘ê°„ë³´ê³ /ìµœì¢…ë³´ê³  í˜•ì‹ìœ¼ë¡œ ì •ë¦¬í•´ì¤˜.
                                              
    [í˜„ì¬ ë³´ê³ ìœ í˜•]
    {report_type}
                                              
    [ì¥ì•  ëŒ€ì‘ í…œí”Œë¦¿]
    {template}

    [ê´€ë ¨ ë¬¸ì„œ ë‚´ìš©]
    {context}

    [ìƒí™©ì°½ ë©”ì‹œì§€]
    {question}
    """)

    # 5ï¸âƒ£ ì²´ì¸ ìƒì„±
    rag_chain = (
        {"context": retriever, "question": RunnablePassthrough(), "report_type": RunnablePassthrough()}
        | prompt
        | llm
    )
except Exception as e:
    st.error(f"LangChain ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    st.stop()


with main_col:
    # ğŸ”¹ ë©”ì¸ í™”ë©´ ì œëª©
    st.title("âš™ï¸ AI ê¸°ë°˜ ì¥ì•  ëŒ€ì‘ ìƒí™©ì°½ ì–´ì‹œìŠ¤í„´íŠ¸")

    # ==============================================
    # ğŸ’¬ TAB 1 - ìƒí™©ì°½ (Chat ê¸°ëŠ¥)
    # ==============================================
    if st.session_state.active_tab == "tab1":
        if "is_generating" not in st.session_state:
            st.session_state.is_generating = False
        st.markdown("<div class='tab-div tab1-div'>", unsafe_allow_html=True)
        st.markdown("### ğŸŸ¤ ìƒí™©ì°½ ë¶„ì„ (í™œì„±í™”ë¨)")

        chat_container = st.container()

        # âœ… ëŒ€í™” ì¶œë ¥
        if not st.session_state.is_generating:
            with chat_container:
                for msg in st.session_state.messages:
                    # spinner ì‹¤í–‰ ì¤‘ì—ëŠ” assistant ë©”ì‹œì§€ ìˆ¨ê¸°ê¸°
                    if st.session_state.get("is_generating") and msg["role"] == "assistant":
                        continue  # ğŸ”¹ ì´ì „ ì–´ì‹œìŠ¤í„´íŠ¸ ë©”ì‹œì§€ ì¶œë ¥ ì•ˆ í•¨

                    role_class = "user-msg" if msg["role"] == "user" else "assistant-msg"
                    st.markdown(
                        "<div class='chat-bubble {}'>{}</div>".format(role_class, msg["content"].replace("\n", "<br>")),
                        unsafe_allow_html=True
                    )

        st.markdown("""
            <style>
            /* ì…ë ¥ì°½ ì „ì²´ ì˜ì—­ í•˜ë‹¨ ê³ ì • */
            [data-testid="stChatInput"] {
                position: fixed;
                bottom: 0;
                left: 24%;            /* âœ… ì¢Œì¸¡ ì—¬ë°± â€” ì¡°ì • ê°€ëŠ¥ */
                width: 55%;           /* âœ… ì…ë ¥ì°½ ì „ì²´ í­ â€” ì¤‘ì•™ main_col í¬ê¸°ì— ë§ê²Œ */
                z-index: 999;
                background-color: white;
                border-top: 1px solid #ddd;
                padding-top: 8px;
            }
            </style>
            """, unsafe_allow_html=True)
        # ì…ë ¥ì°½ í•˜ë‹¨ ê³ ì •
        user_input = st.chat_input("ğŸ—¨ ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”...")

        if user_input:
            # ì‚¬ìš©ì ë©”ì‹œì§€
            st.markdown(
                "<div class='chat-bubble user-msg'>{}</div>".format(user_input.replace("\n", "<br>")),
                unsafe_allow_html=True
            )
                        
            #st.chat_message("user").markdown(user_input.replace("\n", "<br>"), unsafe_allow_html=True)
            st.session_state["messages"].append({"role": "user", "content": user_input})

            # ë³´ê³ ì„œ ìœ í˜• íŒë‹¨
            report_type = "ìµœì¢…ë³´ê³ " if ("ë³µêµ¬ ì™„ë£Œ" in user_input or "ì „ì²´ ì™„ë£Œ" in user_input or "ì´ìƒ ì—†ìŒ ë³´ê³ " in user_input) else "ì¤‘ê°„ë³´ê³ "

            # ëŒ€í™” ì´ë ¥ í¬í•¨
            chat_history = "\n".join([f"{m['role']}: {m['content']}" for m in st.session_state["messages"]])
            query_with_context = f"{chat_history}\nuser: {user_input}"

            st.session_state.is_generating = True
            with st.spinner("AIê°€ "+report_type+"ë¥¼ ì‘ì„±ì¤‘ì…ë‹ˆë‹¤..."):
                try:
                    rag_input = {"question": query_with_context, "template": incident_template, "report_type": report_type}

                    retriever_output = retriever.invoke(query_with_context)
                    context_texts = "\n".join([d.page_content for d in retriever_output]) if retriever_output else ""

                    prompt_input = {
                        "context": context_texts,
                        "question": query_with_context,
                        "template": incident_template,
                        "report_type": report_type
                    }

                    # ğŸ”¹ LLM í˜¸ì¶œ
                    raw_llm_response = llm.invoke(prompt.format(**prompt_input))
                    ai_output = str(raw_llm_response)

                    print("\nğŸ” input: "+ prompt.format(**prompt_input))
                    print("\nğŸ” output: "+ ai_output)
            

                    # ğŸ”¹ content ë¶€ë¶„ë§Œ ì¶”ì¶œ
                    match = re.search(r"content='(.*?)' additional_kwargs=", ai_output, re.DOTALL)
                    if match:
                        content_text = match.group(1).strip()
                    else:
                        content_text = ai_output.strip()

                    # \n â†’ ì¤„ë°”ê¿ˆ ë³µì›
                    content_text = content_text.replace("\\n", "\n")

                    #st.chat_message("assistant").markdown(content_text)
                    # st.session_state.messages.append({"role": "assistant", "content": content_text})
                    # role_class = "assistant-msg"
                    # st.markdown(f"<div class='chat-bubble {role_class}'>{content_text}</div>", unsafe_allow_html=True)
                    # âœ… AI ì‘ë‹µ ì¦‰ì‹œ í‘œì‹œ (rerun ì¤‘ë³µ ë°©ì§€)
                    st.markdown(
                        "<div class='chat-bubble assistant-msg'>{}</div>".format(content_text.replace("\n", "<br>")),
                        unsafe_allow_html=True
                    )

                    # âœ… rerun ì´í›„ì—ë„ ìœ ì§€ë˜ë„ë¡ ì„¸ì…˜ì— ì¶”ê°€
                    st.session_state.messages.append({"role": "assistant", "content": content_text})


                    st.session_state.reports.append({
                        "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                        "type": report_type,
                        "content": ai_output
                    })
                    
                    # ë¡œê·¸ ì €ì¥
                    log_data = {
                        "timestamp": datetime.now().isoformat(),
                        "role": "assistant",
                        "report_type": report_type,
                        "input": user_input,
                        "output": ai_output
                    }

                    with open(log_path, "a", encoding="utf-8") as f:
                        json.dump(log_data, f, ensure_ascii=False)
                        f.write("\n")

                except Exception as e:
                    st.error(f"RAG ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

            st.session_state.is_generating = False

            # ìë™ ìŠ¤í¬ë¡¤
            st.markdown("""
                <script>
                var chatDiv = window.parent.document.querySelector('.stMarkdown');
                if (chatDiv) { chatDiv.scrollTop = chatDiv.scrollHeight; }
                </script>
            """, unsafe_allow_html=True)
            
            st.markdown("</div>", unsafe_allow_html=True)

    # ==============================================
    # ğŸ“ TAB 2 - ë³´ê³ ì„œ
    # ==============================================
    elif st.session_state.active_tab == "tab2":
        st.markdown("<div class='tab-div tab2-div'>", unsafe_allow_html=True)
        st.markdown("### âšª ë³´ê³ ì„œ ë‚´ì—­")

        if st.session_state.reports:
            latest_report = st.session_state.reports[-1]
            st.markdown(f"#### ğŸ“„ ìµœì‹  ë³´ê³ ì„œ ({latest_report['timestamp']})")
            st.markdown(f"**ìœ í˜•:** {latest_report['type']}")
            st.markdown("---")
            raw_text = latest_report["content"]
            match = re.search(r"content='(.*?)' additional_kwargs=", raw_text, re.DOTALL)
            cleaned_text = match.group(1).strip() if match else raw_text.strip()
            cleaned_text = cleaned_text.replace("\\n", "\n")
            st.markdown(cleaned_text)

            # ì „ì²´ ë³´ê³ ì„œ íˆìŠ¤í† ë¦¬
            with st.expander("ğŸ“š ì „ì²´ ë³´ê³ ì„œ ê¸°ë¡ ë³´ê¸°"):
                for r in reversed(st.session_state.reports):
                    st.markdown(f"- ğŸ•“ `{r['timestamp']}` | **{r['type']}**")
                    raw_text = r["content"]
                    match = re.search(r"content='(.*?)' additional_kwargs=", raw_text, re.DOTALL)
                    cleaned_text = match.group(1).strip() if match else raw_text.strip()
                    cleaned_text = cleaned_text.replace("\\n", "\n")
                    st.markdown(f"> {cleaned_text}")

        else:
            st.info("ì•„ì§ ìƒì„±ëœ ë³´ê³ ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")

        st.markdown("</div>", unsafe_allow_html=True)


with right_col:
    st.markdown("### ğŸ’¡ ì¥ì•  ë°œìƒ ìƒí™©ì°½")

    with open("data/sample_incident_chat.txt", "r", encoding="utf-8") as f:
        content = f.read()
        quotes = [q.strip() for q in content.split("|||") if q.strip()]

    if "random_quote" not in st.session_state:
        st.session_state["random_quote"] = random.choice(quotes)

    quote_html = st.session_state["random_quote"].replace("\\n", "<br>").replace("\n", "<br>")

    st.markdown(f"""
    <div style="
        background-color:#f8f9fa;
        border-radius:8px;
        padding:12px;
        border:1px solid #ddd;
        line-height:1.5;
    ">
    {quote_html}
    </div>
    """, unsafe_allow_html=True)

    if st.button("ğŸ”„ ìƒí™©ì°½ ìƒˆë¡œê³ ì¹¨", use_container_width=True):
        st.session_state["random_quote"] = random.choice(quotes)
        st.rerun()